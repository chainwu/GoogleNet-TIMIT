{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5d2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.models import Model,load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model,np_utils\n",
    "from keras import regularizers\n",
    "import keras.metrics as metric\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da8168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 15:17:48.693147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-18 15:17:48.725760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 15:17:48.725858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-04-18 15:17:48.725971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-18 15:17:48.726914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-18 15:17:48.727790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-18 15:17:48.727955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-18 15:17:48.728881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-18 15:17:48.729387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-18 15:17:48.731449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-18 15:17:48.731512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 15:17:48.731618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 15:17:48.731682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e95c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45316 images belonging to 61 classes.\n",
      "Found 5714 images belonging to 61 classes.\n",
      "Found 18661 images belonging to 61 classes.\n"
     ]
    }
   ],
   "source": [
    "# Global Constants\n",
    "NB_CLASS=61\n",
    "LEARNING_RATE=0.01\n",
    "MOMENTUM=0.9\n",
    "ALPHA=0.0001\n",
    "BETA=0.75\n",
    "GAMMA=0.1\n",
    "DROPOUT=0.4\n",
    "WEIGHT_DECAY=0.0005\n",
    "LRN2D_NORM=True\n",
    "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
    "USE_BN=True\n",
    "IM_WIDTH=256\n",
    "IM_HEIGHT=256\n",
    "EPOCH=5\n",
    "\n",
    "train_root='/home/chainwu/GIT/GoogleNet-Phoneme/TRAIN/'\n",
    "vaildation_root='/home/chainwu/GIT/GoogleNet-Phoneme/VALIDATE/'\n",
    "test_root='/home/chainwu/GIT/GoogleNet-Phoneme/TEST/'\n",
    "\n",
    "#IM_WIDTH=308\n",
    "#IM_HEIGHT=308\n",
    "batch_size=32\n",
    "\n",
    "#train data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=False,\n",
    "    featurewise_center=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#vaild data\n",
    "vaild_datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=False,\n",
    "    featurewise_center=True\n",
    ")\n",
    "vaild_generator = train_datagen.flow_from_directory(\n",
    "  vaildation_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=False,\n",
    "    featurewise_center=True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "  test_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#normalization\n",
    "def conv2D_lrn2d(x,filters,kernel_size,strides=(1,1),padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=WEIGHT_DECAY):\n",
    "    #l2 normalization\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "\n",
    "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    if lrn2d_norm:\n",
    "        #batch normalization\n",
    "        x=BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def inception_module(x,params,concat_axis,padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=None):\n",
    "    (branch1,branch2,branch3,branch4)=params\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "    #1x1\n",
    "    pathway1=Conv2D(filters=branch1[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    #1x1->3x3\n",
    "    pathway2=Conv2D(filters=branch2[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway2=Conv2D(filters=branch2[1],kernel_size=(3,3),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway2)\n",
    "\n",
    "    #1x1->5x5\n",
    "    pathway3=Conv2D(filters=branch3[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway3=Conv2D(filters=branch3[1],kernel_size=(5,5),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway3)\n",
    "\n",
    "    #3x3->1x1\n",
    "    pathway4=MaxPooling2D(pool_size=(3,3),strides=1,padding=padding,data_format=DATA_FORMAT)(x)\n",
    "    pathway4=Conv2D(filters=branch4[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway4)\n",
    "\n",
    "    return concatenate([pathway1,pathway2,pathway3,pathway4],axis=concat_axis)\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    #Data format:tensorflow,channels_last;theano,channels_last\n",
    "    if DATA_FORMAT=='channels_first':\n",
    "        INP_SHAPE=(3,IM_WIDTH,IM_HEIGHT)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=1\n",
    "    elif DATA_FORMAT=='channels_last':\n",
    "        INP_SHAPE=(IM_WIDTH,IM_HEIGHT,3)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=3\n",
    "    else:\n",
    "        raise Exception('Invalid Dim Ordering')\n",
    "\n",
    "    x=conv2D_lrn2d(img_input,64,(7,7),2,padding='same',lrn2d_norm=False)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "\n",
    "    x=conv2D_lrn2d(x,64,(1,1),1,padding='same',lrn2d_norm=False)\n",
    "\n",
    "    x=conv2D_lrn2d(x,192,(3,3),1,padding='same',lrn2d_norm=True)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(64,),(96,128),(16,32),(32,)],concat_axis=CONCAT_AXIS) #3a\n",
    "    x=inception_module(x,params=[(128,),(128,192),(32,96),(64,)],concat_axis=CONCAT_AXIS) #3b\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(192,),(96,208),(16,48),(64,)],concat_axis=CONCAT_AXIS) #4a\n",
    "    x=inception_module(x,params=[(160,),(112,224),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4b\n",
    "    x=inception_module(x,params=[(128,),(128,256),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4c\n",
    "    x=inception_module(x,params=[(112,),(144,288),(32,64),(64,)],concat_axis=CONCAT_AXIS) #4d\n",
    "    x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #4e\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #5a\n",
    "    x=inception_module(x,params=[(384,),(192,384),(48,128),(128,)],concat_axis=CONCAT_AXIS) #5b\n",
    "    x=AveragePooling2D(pool_size=(7,7),strides=1,padding='valid',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dropout(DROPOUT)(x)\n",
    "    x=Dense(NB_CLASS,activation='linear')(x)\n",
    "    x=Dense(NB_CLASS,activation='softmax')(x)\n",
    "\n",
    "    return x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create the Model\n",
    "    x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT=create_model()\n",
    "\n",
    "    # Create a Keras Model\n",
    "    model=Model(img_input,[x])\n",
    "    model.summary()\n",
    "\n",
    "    # Save a PNG of the Model Build\n",
    "    plot_model(model,to_file='GoogLeNet.png')\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc',metric.top_k_categorical_accuracy])\n",
    "    print('Model Compiled')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fbf255",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1417/1416 [==============================] - 93s 65ms/step - loss: 0.7721 - acc: 0.7620 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.3009 - val_acc: 0.6351 - val_top_k_categorical_accuracy: 0.9328\n",
      "Epoch 2/5\n",
      "1417/1416 [==============================] - 93s 65ms/step - loss: 0.7419 - acc: 0.7671 - top_k_categorical_accuracy: 0.9786 - val_loss: 1.9229 - val_acc: 0.5131 - val_top_k_categorical_accuracy: 0.8504\n",
      "Epoch 3/5\n",
      "1417/1416 [==============================] - 93s 65ms/step - loss: 0.7318 - acc: 0.7710 - top_k_categorical_accuracy: 0.9779 - val_loss: 1.3663 - val_acc: 0.6323 - val_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 4/5\n",
      "1417/1416 [==============================] - 93s 65ms/step - loss: 0.7167 - acc: 0.7774 - top_k_categorical_accuracy: 0.9799 - val_loss: 1.4271 - val_acc: 0.6274 - val_top_k_categorical_accuracy: 0.9291\n",
      "Epoch 5/5\n",
      "1417/1416 [==============================] - 92s 65ms/step - loss: 0.7133 - acc: 0.7760 - top_k_categorical_accuracy: 0.9792 - val_loss: 1.4021 - val_acc: 0.6390 - val_top_k_categorical_accuracy: 0.9323\n",
      "--- Testing ---\n",
      "Test result:loss:1.554122,acc:0.613740,top_acc:0.912170\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    if os.path.exists('inception_1.h5'):\n",
    "        model=load_model('inception_1.h5')\n",
    "    else:\n",
    "        model=check_print()\n",
    "\n",
    "    model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "                        ,validation_steps=vaild_generator.n/batch_size)\n",
    "    model.save('inception_1.h5')\n",
    "    #model.metrics=['acc',metric.top_k_categorical_accuracy]\n",
    "    print(\"--- Testing ---\")\n",
    "    loss,acc,top_acc=model.evaluate_generator(test_generator,steps=test_generator.n/batch_size)\n",
    "    print('Test result:loss:%f,acc:%f,top_acc:%f'%(loss,acc,top_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faac5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ff82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
